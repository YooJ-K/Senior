{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"video_detect.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1TemKJUhYiAJAq1nVeBjOxsZ01UbmpYcD","authorship_tag":"ABX9TyNZP7FTs42WMXgDwHtZQgr/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WvVfcVRAKhH2"},"source":["######## Video Object Detection Using Tensorflow-trained Classifier #########\n","#\n","# Author: Evan Juras\n","# Date: 1/16/18\n","# Description:\n","# This program uses a TensorFlow-trained classifier to perform object detection.\n","# It loads the classifier uses it to perform object detection on a video.\n","# It draws boxes and scores around the objects of interest in each frame\n","# of the video.\n","## Some of the code is copied from Google's example at\n","## https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n","## and some is copied from Dat Tran's example at\n","## https://github.com/datitran/object_detector_app/blob/master/object_detection_app.py\n","## but I changed it to make it more understandable to me.\n","# Import packages"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pOF1ESo5LZE5","executionInfo":{"status":"ok","timestamp":1622420914780,"user_tz":-540,"elapsed":60384,"user":{"displayName":"세상이요지경","photoUrl":"","userId":"08831440865401949465"}},"outputId":"1446a003-c305-469d-ae12-56c440ee366c"},"source":["!pip install -U --pre tensorflow==\"1.15.*\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.15.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/51/99abd43185d94adaaaddf8f44a80c418a91977924a7bc39b8dacd0c495b0/tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n","\u001b[K     |████████████████████████████████| 110.5MB 80kB/s \n","\u001b[?25hCollecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.*) (3.3.0)\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 32.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.*) (3.12.4)\n","Collecting h5py<=2.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 30.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.*) (1.12.1)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.*) (0.2.0)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.*) (1.1.2)\n","Collecting numpy<1.19.0,>=1.16.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n","\u001b[K     |████████████████████████████████| 20.1MB 1.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.*) (1.15.0)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.*) (1.34.1)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.*) (1.1.0)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.*) (0.36.2)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.*) (0.8.1)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.*) (0.12.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 29.2MB/s \n","\u001b[?25hCollecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.*) (56.1.0)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.*) (3.3.4)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.*) (1.0.1)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.*) (4.0.1)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.*) (3.4.1)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.*) (3.7.4.3)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=8d293ef2e5800c9d1defcb3def44e07264a35e622ce7d18aeff1e8a0fff91d62\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, h5py, keras-applications, tensorflow-estimator, tensorboard, gast, tensorflow\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Found existing installation: tensorflow-estimator 2.5.0\n","    Uninstalling tensorflow-estimator-2.5.0:\n","      Successfully uninstalled tensorflow-estimator-2.5.0\n","  Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Found existing installation: tensorflow 2.5.0\n","    Uninstalling tensorflow-2.5.0:\n","      Successfully uninstalled tensorflow-2.5.0\n","Successfully installed gast-0.2.2 h5py-2.10.0 keras-applications-1.0.8 numpy-1.18.5 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZmeYOV5JLvyR","executionInfo":{"status":"ok","timestamp":1622420965198,"user_tz":-540,"elapsed":38188,"user":{"displayName":"세상이요지경","photoUrl":"","userId":"08831440865401949465"}},"outputId":"cf5fa2a8-108b-48c0-d084-4a4f70a1b161"},"source":["%%bash\n","cd /content/drive/MyDrive/foreign_kindergarten/models/research/slim\n","pip install .\n","cd /content/drive/MyDrive/foreign_kindergarten/models/research/object_detection/packages/tf1\n","pip install ."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing /content/drive/MyDrive/foreign_kindergarten/models/research/slim\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from slim==0.1) (1.15.0)\n","Collecting tf-slim>=1.1\n","  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim>=1.1->slim==0.1) (0.12.0)\n","Building wheels for collected packages: slim\n","  Building wheel for slim (setup.py): started\n","  Building wheel for slim (setup.py): finished with status 'done'\n","  Created wheel for slim: filename=slim-0.1-cp37-none-any.whl size=231267 sha256=d75648e1a5d9e8829bdaaaa194e351bead47bc72dd3cbae1e389f6789199a2a0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ktanpvvm/wheels/09/1a/a1/cdd3c49b9edeb25cdd969f05a234c57e22315fbdf4290cf08b\n","Successfully built slim\n","Installing collected packages: tf-slim, slim\n","Successfully installed slim-0.1 tf-slim-1.1.0\n","Processing /content/drive/MyDrive/foreign_kindergarten/models/research/object_detection/packages/tf1\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n","Collecting lvis\n","  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.18.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (56.1.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2018.9)\n","Building wheels for collected packages: object-detection\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1169 sha256=119d61ed7d208d4107ec85c8d8fffd79be1480083ad3183c150d24b8bc370bb8\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-wx7gl1kt/wheels/12/13/87/67a212c9bdf3574576c8dbd6abcd09ea8a254b08f438ab0d63\n","Successfully built object-detection\n","Installing collected packages: lvis, object-detection\n","Successfully installed lvis-0.5.3 object-detection-0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRkyX9IALx7H","executionInfo":{"status":"ok","timestamp":1622420965199,"user_tz":-540,"elapsed":14,"user":{"displayName":"세상이요지경","photoUrl":"","userId":"08831440865401949465"}},"outputId":"bebbd215-7f60-4045-924d-f39bc49a775c"},"source":["%set_env PYTHONPATH=/content/drive/MyDrive/foreign_kindergarten/models/research:/content/drive/MyDrive/foreign_kindergarten/models/research/slim\n","import os\n","os.chdir('/content/drive/MyDrive/foreign_kindergarten/models/research/object_detection')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["env: PYTHONPATH=/content/drive/MyDrive/foreign_kindergarten/models/research:/content/drive/MyDrive/foreign_kindergarten/models/research/slim\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"98kxsn2TKlXs"},"source":["import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","import sys\n","import time\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","# Import utilites\n","from utils import label_map_util\n","from utils import visualization_utils as vis_util\n","\n","from google.colab.patches import cv2_imshow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8cXx_itMJxC"},"source":["# Name of the directory containing the object detection module we're using\n","MODEL_NAME = 'ssd_mobilenet_v2_coco'\n","VIDEO_NAME = '외국 어린이집.mp4'\n","# Grab path to current working directory\n","CWD_PATH = os.getcwd()\n","# Path to frozen detection graph .pb file, which contains the model that is used\n","# for object detection.\n","PATH_TO_CKPT = '/content/drive/MyDrive/foreign_kindergarten/models/research/object_detection/training/frozen_inference_graph.pb'\n","# Path to label map file\n","PATH_TO_LABELS = '/content/drive/MyDrive/foreign_kindergarten/models/research/object_detection/training/labelmap.pbtxt'\n","# Path to video\n","PATH_TO_VIDEO = '/content/drive/MyDrive/foreign_kindergarten/' + VIDEO_NAME\n","# Number of classes the object detector can identify\n","NUM_CLASSES = 2\n","# Load the label map.\n","# Label maps map indices to category names, so that when our convolution\n","# network predicts `5`, we know that this corresponds to `king`.\n","# Here we use internal utility functions, but anything that returns a\n","# dictionary mapping integers to appropriate string labels would be fine\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vwWq91KtMMP4","colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"status":"error","timestamp":1622420972385,"user_tz":-540,"elapsed":2422,"user":{"displayName":"세상이요지경","photoUrl":"","userId":"08831440865401949465"}},"outputId":"3250d1c2-9494-4f36-f8ba-d459ce2854d3"},"source":["# Load the Tensorflow model into memory.\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.compat.v1.GraphDef()\n","    with tf.compat.v1.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","    sess = tf.compat.v1.Session(graph=detection_graph)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-b21000efefbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mod_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_CKPT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mserialized_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mod_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mod_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\"\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m                                            \"File isn't open for reading\")\n\u001b[1;32m     83\u001b[0m       self._read_buf = pywrap_tensorflow.CreateBufferedInputStream(\n\u001b[0;32m---> 84\u001b[0;31m           compat.as_bytes(self.__name), 1024 * 512)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: /content/drive/MyDrive/foreign_kindergarten/models/research/object_detection/training/frozen_inference_graph.pb; No such file or directory"]}]},{"cell_type":"code","metadata":{"id":"qxVvfmSCbIma"},"source":["# Define input and output tensors (i.e. data) for the object detection classifier\n","# Input tensor is the image\n","image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n","# Output tensors are the detection boxes, scores, and classes\n","# Each box represents a part of the image where a particular object was detected\n","detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n","# Each score represents level of confidence for each of the objects.\n","# The score is shown on the result image, together with the class label.\n","detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n","detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n","# Number of objects detected\n","num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n","# Open video file\n","video = cv2.VideoCapture(PATH_TO_VIDEO)\n","prevTime = 0 #이전 시간을 저장할 변수"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NvyxP4RDbKk1"},"source":["width = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n","height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n","\n","fps = video.get(cv2.CAP_PROP_FPS)\n","fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n","\n","new_file_name = '/content/drive/MyDrive/foreign_kindergarten/models/research/object_detection/training/detection_foreign_kindergarten.mp4'\n","\n","#save_video = cv2.VideoWriter(new_file_name, fourcc, fps, (int(width), int(height)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6VhIHdrKelV"},"source":["while(video.isOpened()):\n","    # Acquire frame and expand frame dimensions to have shape: [1, None, None, 3]\n","    # i.e. a single-column array, where each item in the column has the pixel RGB value\n","    ret, frame = video.read()\n","    frame_expanded = np.expand_dims(frame, axis=0)\n","    # Perform the actual detection by running the model with the image as input\n","    (boxes, scores, classes, num) = sess.run(\n","        [detection_boxes, detection_scores, detection_classes, num_detections],\n","        feed_dict={image_tensor: frame_expanded})\n","    # Draw the results of the detection (aka 'visulaize the results')\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        frame,\n","        np.squeeze(boxes),\n","        np.squeeze(classes).astype(np.int32),\n","        np.squeeze(scores),\n","        category_index,\n","        use_normalized_coordinates=True,\n","        line_thickness=8,\n","        min_score_thresh=0.80)\n","    curTime = time.time()\n","    # 한번 돌아온 시간!!\n","    sec = curTime - prevTime\n","    # 이전 시간을 현재시간으로 다시 저장시킴\n","    prevTime = curTime\n","    # 프레임 계산 한바퀴 돌아온 시간을 1초로 나누면 된다.\n","    # 1 / time per frame\n","    fps = 1 / (sec)\n","    # 디버그 메시지로 확인해보기\n","    print (\"Time {0} \".format(sec))\n","    print (\"Estimated fps {0} \".format(fps))\n","    # 프레임 수를 문자열에 저장\n","    str = \"FPS : %0.1f\" % fps\n","    # 표시\n","    cv2.putText(frame, str, (0, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))\n","    # All the results have been drawn on the frame, so it's time to display it.\n","    cv2_imshow(frame)\n","    #save_video.write(frame)\n","    # Press 'q' to quit\n","    if cv2.waitKey(1) == ord('q'):\n","        break\n","# Clean up\n","video.release()\n","#save_video.release()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]}]}